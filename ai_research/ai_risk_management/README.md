# AI Risk Management Frameworks and AI Security Resources

## NIST Resources
- [NIST Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework): used to to improve the ability to incorporate trustworthiness considerations into the design, development, use, and evaluation of AI products, services, and systems.
- [Roadmap for the NIST Artificial Intelligence Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework/roadmap-nist-artificial-intelligence-risk-management-framework-ai)
- [NIST "Language of Trustworthy AI: An In-Depth Glossary of Terms" ](https://airc.nist.gov/AI_RMF_Knowledge_Base/Glossary)
- [NIST AI Technical and Policy Documents](https://airc.nist.gov/AI_RMF_Knowledge_Base/Technical_And_Policy_Documents)
- [US AI Safety Institute](https://www.nist.gov/artificial-intelligence/artificial-intelligence-safety-institute): Established in 2024 to advance AI safety research, standards, and testing

## Europe

- [European AI Act](https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai): Came into force August 2024, establishing comprehensive AI regulation framework
- [AI Strategy in Europe](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=COM%3A2018%3A237%3AFIN)
- [European Commission Artificial Intelligence – Questions and Answers](https://ec.europa.eu/commission/presscorner/detail/en/QANDA_21_1683)
- [EU AI Act Implementation Guide](https://digital-strategy.ec.europa.eu/en/library/artificial-intelligence-act-implementation): Official implementation guidance for organizations

## Canada
- [Artificial Intelligence and Data Act](https://ised-isde.canada.ca/site/innovation-better-canada/en/artificial-intelligence-and-data-act)
- [Canadian Guardrails for Generative AI – Code of Practice](https://ised-isde.canada.ca/site/ised/en/consultation-development-canadian-code-practice-generative-artificial-intelligence-systems/canadian-guardrails-generative-ai-code-practice)

## Asia-Pacific
- [Singapore Model AI Governance Framework](https://www.pdpc.gov.sg/help-and-resources/2020/01/model-ai-governance-framework): Updated 2024 version with enhanced cybersecurity considerations
- [Japan AI Governance Guidelines](https://www.meti.go.jp/english/policy/mono_info_service/connected_industries/ai.html): 2024 updates for AI system security and risk management
- [Australia AI Ethics Framework](https://www.industry.gov.au/data-and-publications/building-australias-artificial-intelligence-capability/ai-ethics-framework): Enhanced with cybersecurity risk assessments

## ISO
- [ISO AI Website](https://www.iso.org/sectors/it-technologies/ai)
- [ISO/IEC 42001:2023 Artificial intelligence Management system](https://www.iso.org/standard/81230.html)
- [ISO/IEC 23894:2023 Artificial intelligence Guidance on risk management](https://www.iso.org/standard/77304.html)
- [ISO/IEC 23053:2022 Framework for Artificial Intelligence (AI) Systems Using Machine Learning (ML)](https://www.iso.org/standard/74438.html)

## Cloud Security Alliance
- [CSA's Securing LLM Backed Systems: Essential Authorization Practices](https://github.com/The-Art-of-Hacking/h4cker/blob/master/ai_research/ai_risk_management/Securing%20LLM%20Backed%20Systems%20-%20Essential%20Authorization%20Practices%2020240806.pdf)

## US Government Resources

- [NSA/DoD - Joint Guidance on Deploying AI Systems Securely](https://media.defense.gov/2024/Apr/15/2003439257/-1/-1/0/CSI-DEPLOYING-AI-SYSTEMS-SECURELY.PDF)
- [CISA AI Cybersecurity Best Practices](https://www.cisa.gov/ai): 2024 guidance on securing AI systems and infrastructure
- [White House AI Executive Order](https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/): Executive Order on Safe, Secure, and Trustworthy AI

## Additional Securing AI Resources

- [MITRE ATLAS](https://atlas.mitre.org/): Adversarial Threat Landscape for Artificial-Intelligence Systems
- [OWASP Top 10 for LLM Applications](https://genai.owasp.org/): Updated 2024 version with latest LLM vulnerabilities
- [OWASP AI Security and Privacy Guide](https://owasp.org/www-project-ai-security-and-privacy-guide/)
- [OWASP Machine Learning Security Top 10](https://mltop10.info/): Comprehensive ML security risks framework
- [Securing Your AI: A Step-by-Step Guide for CISOs](https://hiddenlayer.com/research/how-well-do-you-know-your-ai-environment/)
- [Securing Your AI: A Step-by-Step Guide for CISOs PT 2](https://hiddenlayer.com/research/securing-your-ai-a-step-by-step-guide-for-cisos-pt2/)
- [CSA Securing LLM Backed Systems](https://github.com/The-Art-of-Hacking/h4cker/blob/master/ai_research/ai_risk_management/Securing%20LLM%20Backed%20Systems%20-%20Essential%20Authorization%20Practices%2020240806.pdf)
## Industry-Specific Resources
- [Financial Services AI Risk Management](https://www.federalreserve.gov/supervisionreg/srletters/SR2404.htm): Federal Reserve guidance on AI/ML risk management for banks
- [Healthcare AI Security Framework](https://www.hhs.gov/about/news/2024/01/09/hhs-announces-new-artificial-intelligence-strategy.html): HHS AI strategy including cybersecurity requirements
- [Automotive AI Safety Standards](https://www.iso.org/standard/70939.html): ISO 21448 for AI in automotive systems

## Academia
- [MIT AI Risk Database](https://airisk.mit.edu/): Comprehensive database of AI incidents and risks
- [Stanford AI Index Report 2024](https://aiindex.stanford.edu/report/): Annual report including AI safety and security trends
- [Berkeley Center for AI Safety](https://www.safe.ai/): Research on AI alignment and safety
